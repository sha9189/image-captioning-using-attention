{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596779766250",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellanous   \n",
    "This notebook contains all the intermediate steps and calculations during modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Dev image sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file containing all caption-image pairs\n",
    "with open('Dataset/Flickr30k/Flickr30k.token.txt', 'r') as file:\n",
    "    annotations = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to the image folder\n",
    "PATH = os.path.abspath('.') + '/Dataset/Flickr30k/flickr30k-images/'\n",
    "\n",
    "# Store captions and image names in vectors\n",
    "all_captions = []\n",
    "all_img_name_vector = []\n",
    "\n",
    "# splitting the file contents by line\n",
    "for annot in annotations.split(\"\\n\"):\n",
    "        # Skip empty lines\n",
    "        if len(annot)<1:\n",
    "            continue\n",
    "        # separate out the caption from the line\n",
    "        caption = annot.split()[1:]\n",
    "        # add <start> and <end> token to the caption\n",
    "        caption = \"<start> \" + ' '.join(caption) + \" <end>\"\n",
    "        # separate out the image id from line)\n",
    "        image_id = annot.split()[0]\n",
    "        # remove caption number\n",
    "        image_id = image_id.split('#')[0]\n",
    "        # convert image id into the image path\n",
    "        full_image_path = PATH + image_id\n",
    "\n",
    "        all_img_name_vector.append(full_image_path)\n",
    "        all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(158915,\n '/home/shailesh/Projects/mytf2/Flickr30k_notebooks/Dataset/Flickr30k/flickr30k-images/1000092795.jpg',\n '<start> Two young guys with shaggy hair look at their hands while hanging out in the yard . <end>')"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "len(all_captions), all_img_name_vector[0], all_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide images into dev and train set\n",
    "encode_train = sorted(set(all_img_name_vector))\n",
    "\n",
    "encode_train = shuffle(encode_train, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "29783"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# last 2k images be dev set\n",
    "len(encode_train)-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(\"Flickr_30k.trainImages.txt\", 'w')\n",
    "for id in encode_train[:29783]:\n",
    "    id = id.split('/')[-1]\n",
    "    train_file.write(id+'\\n')\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file = open(\"Flickr_30k.devImages.txt\", 'w')\n",
    "for id in encode_train[29783:]:\n",
    "    id = id.split('/')[-1]\n",
    "    dev_file.write(id+'\\n')\n",
    "\n",
    "dev_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab Size Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file containing all caption-image pairs\n",
    "with open('Dataset/Flickr30k/Flickr30k.token.txt', 'r') as file:\n",
    "    annotations = file.read()\n",
    "\n",
    "# to load the predefined list of image identfiers for training and validation set\n",
    "def load_set(filename):\n",
    "    \"\"\"loads the set of identifiers in `filename`\"\"\"\n",
    "    # read the file contents\n",
    "    with open(filename, 'r') as file:\n",
    "        doc = file.read()\n",
    "    dataset = list()\n",
    "    # process line by line\n",
    "    for line in doc.split('\\n'):\n",
    "        # skip empty lines\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        # get the image identifier\n",
    "        # identifier = line.split('.')[0]\n",
    "        dataset.append(line)\n",
    "    return set(dataset)\n",
    "\n",
    "# load the train set identifiers\n",
    "train_set = load_set('Dataset/Flickr30k/Flickr_30k.trainImages.txt')\n",
    "\n",
    "# load the validation set identifiers\n",
    "val_set = load_set('Dataset/Flickr30k/Flickr_30k.devImages.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(29783, 2000)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to the image folder\n",
    "PATH = os.path.abspath('.') + '/Dataset/Flickr30k/flickr30k-images'\n",
    "\n",
    "# Store captions and image names in vectors\n",
    "train_captions = []\n",
    "img_name_train = []\n",
    "val_captions = []\n",
    "img_name_val = []\n",
    "\n",
    "# splitting the file contents by line\n",
    "for annot in annotations.split(\"\\n\"):\n",
    "        # Skip empty lines\n",
    "        if len(annot)<1:\n",
    "            continue\n",
    "        # separate out the caption from the line\n",
    "        caption = annot.split()[1:]\n",
    "        # add <start> and <end> token to the caption\n",
    "        caption = \"<start> \" + ' '.join(caption) + \" <end>\"\n",
    "        # separate out the image id from line)\n",
    "        image_id = annot.split()[0]\n",
    "        # remove caption number\n",
    "        image_id = image_id.split('#')[0]\n",
    "        # convert image id into the image path\n",
    "        full_image_path = PATH + image_id\n",
    "\n",
    "        # add the image id and caption in the repective lists\n",
    "        if image_id in train_set:\n",
    "            train_captions.append(caption)\n",
    "            img_name_train.append(full_image_path)\n",
    "        elif image_id in val_set:\n",
    "            val_captions.append(caption)\n",
    "            img_name_val.append(full_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(148915, 148915, 10000, 10000)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(train_captions), len(img_name_train), len(val_captions), len(img_name_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions, img_name_train = shuffle(train_captions, img_name_train, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for line in train_captions:\n",
    "    for word in line.split():\n",
    "        if word not in string.punctuation:\n",
    "            all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('deserts', 4),\n ('inn', 4),\n ('anthem', 4),\n ('shanty', 4),\n ('cushions', 4),\n ('Interracial', 4),\n ('scrub', 4),\n ('flings', 4),\n ('Twenty', 4),\n ('Kiss', 4)]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "word_count.most_common(8000)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "22796"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "for key, count in dropwhile(lambda key_count: key_count[1] >= 5, word_count.most_common()):\n",
    "     del word_count[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7939"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab_size=8k => removing all words appearing less than 5 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare pretrained embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create tokenizer\n",
    "2. load glove vector\n",
    "3. compare the 2 word vectors and get the words not in glove\n",
    "4. replace tokenizer index with `<unk>` for those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Create Tokenizer\n",
    "\n",
    "# choose the top 5000 words from the vocabulary\n",
    "top_k = 8000\n",
    "\n",
    "# create tokenizer object that uses <unk> for out-of-vocabulary words and filters out all punctuations\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, oov_token='<unk>', filters = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "\n",
    "# fit tokenizer on train captions\n",
    "tokenizer.fit_on_texts(train_captions)\n",
    "\n",
    "# add token for padding\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# convert train captions to tokenized sequences\n",
    "train_seqs = tokenizer.texts_to_sequences(train_captions) # output shape = (number_of_captions, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loaded 1917494 word vectors.\n"
    }
   ],
   "source": [
    "## 2. Load Glove Vector\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('../Datasets/glove.42B.300d.txt', 'r')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = np.float32)\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "## 3. Compare the two vocabularies and get the words not in glove\n",
    "\n",
    "# All indexes >=8000 are referred to as <unk>. \n",
    "# Below vocab_size excludes <pad> as list in RHS has pad at the end of list and gets excluded after slicing\n",
    "vocab_words = list(tokenizer.word_index.keys())[:7999]\n",
    "glove_words = list(embeddings_index.keys())\n",
    "\n",
    "not_in_glove = list()\n",
    "for our_word in vocab_words:\n",
    "    if our_word not in glove_words:\n",
    "        not_in_glove.append(our_word)\n",
    "\n",
    "len(not_in_glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(['whil', '<pad>'], 'waterskies')"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "list(tokenizer.word_index.keys())[-2:], list(tokenizer.word_index.keys())[7999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'sheriff'"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "list(tokenizer.word_index.keys())[7998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('sheriff', 56, '<pad>')"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "tokenizer.index_word[7999], tokenizer.word_index['outside'], list(tokenizer.word_index.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['rollerskaters',\n 'surfboarder',\n 'graffited',\n 'parasailer',\n 'outstreached',\n 'ggauged']"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "not_in_glove = not_in_glove[3:]\n",
    "not_in_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "## 4. replace tokenizer index with <unk> for those words\n",
    "tokenizer.word_index['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "rollerskaters 4525\nsurfboarder 5758\ngraffited 5768\nparasailer 6096\noutstreached 6752\nggauged 7953\n"
    }
   ],
   "source": [
    "# that word is converted to <unk> token and that word's token is converted to <unk>\n",
    "unk_idxs = []\n",
    "for word in not_in_glove:\n",
    "    index = tokenizer.word_index[word]\n",
    "    unk_idxs.append(index)\n",
    "    print(word, index)\n",
    "    tokenizer.word_index[word] = 1\n",
    "    tokenizer.index_word[index] = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[4525, 5758, 5768, 6096, 6752, 7953]"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "unk_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[179, 10, 2, 31], [1, 1, 1, 1, 1, 1, 2720, 70]]"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# testing\n",
    "tokenizer.texts_to_sequences(['He is a boy', 'rollerskaters surfboarder graffited parasailer outstreached ggauged test over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['is wearing',\n '<unk> <unk> <unk> <unk> <unk> <unk> midst checkout parading <unk>']"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[10, 20], [4525, 5758, 5768, 6096, 6752, 7953, 2000, 3000, 5000, 10000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer\n",
    "with open('tokenizer-8k-vocab.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unk-idxs.pkl', 'wb') as file:\n",
    "    pickle.dump(unk_idxs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved files\n",
    "with open('tokenizer-8k-vocab.pkl', 'rb') as file:\n",
    "    token = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unk-idxs.pkl', 'rb') as file:\n",
    "    unk_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['is wearing',\n '<unk> <unk> <unk> <unk> <unk> <unk> midst checkout parading <unk>']"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "token.sequences_to_texts([[10, 20], [4525, 5758, 5768, 6096, 6752, 7953, 2000, 3000, 5000, 10000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[179, 10, 2, 31], [1, 1, 1, 1, 1, 1, 2720, 70]]"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "token.texts_to_sequences(['He is a boy', 'rollerskaters surfboarder graffited parasailer outstreached ggauged test over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "unk_list==unk_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weight matrix for Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create weight matrix for all words in word vec\n",
    "2. Create special vectors for unique tokens\n",
    "3. Extend the word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved files\n",
    "with open('tokenizer-8k-vocab.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unk-idxs.pkl', 'rb') as file:\n",
    "    unk_idxs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special tokens: `<start>, <end>, <unk>, <pad>`   \n",
    "1. For `<pad>`, emb vector would be a zero vector as there would be no training for it and it should not convey any meaning.   \n",
    "2. For `<start>, <end> and <unk>`, special column would be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_index > glove_embeddings dict\n",
    "# embedding_matrix > weights matrix for our Embedding\n",
    "\n",
    "# from tokenizer definition above\n",
    "top_k=8000\n",
    "embedding_dim=303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No vector found for: <unk> 1\nNo vector found for: <start> 3\nNo vector found for: <end> 4\nNo vector found for: rollerskaters 1\nNo vector found for: surfboarder 1\nNo vector found for: graffited 1\nNo vector found for: parasailer 1\nNo vector found for: outstreached 1\nNo vector found for: ggauged 1\nNo vector found for: <pad> 0\n"
    }
   ],
   "source": [
    "vocab_size = top_k\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "# iterate over each word in tokenizer, \n",
    "# get the pretrained weights, add the extra columns for special tokens \n",
    "# and replace its vector representation in embedding_matrix\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i>=8000:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_vector = np.append(embedding_vector, np.zeros(3))\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        print(\"No vector found for:\", word, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]))"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "start_vector = np.zeros((embedding_dim,))\n",
    "start_vector[300] = 1\n",
    "end_vector = np.zeros((embedding_dim,))\n",
    "end_vector[301] = 1\n",
    "unk_vector = np.zeros((embedding_dim,))\n",
    "unk_vector[302] = 1\n",
    "start_vector[-4:], end_vector[-4:], unk_vector[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrix[3] = start_vector\n",
    "embedding_matrix[4] = end_vector\n",
    "embedding_matrix[1] = unk_vector\n",
    "\n",
    "# Make all the words not in glove vocab as unk vector\n",
    "for idx in unk_idxs:\n",
    "    # print ((embedding_matrix[idx]==np.zeros((vocab_size, 303))).all())\n",
    "    embedding_matrix[idx] = unk_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding matrix to use for embedding layer in model\n",
    "with open(\"embedding_matix.pkl\", 'wb') as file:\n",
    "    pickle.dump(embedding_matrix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the saved file\n",
    "with open(\"embedding_matix.pkl\", 'rb') as file:\n",
    "    emb_mat = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "(emb_mat==embedding_matrix).all()"
   ]
  }
 ]
}